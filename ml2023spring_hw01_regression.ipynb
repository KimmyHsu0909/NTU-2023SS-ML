{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "version": "3.6.4",
   "file_extension": ".py",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "name": "python",
   "mimetype": "text/x-python"
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "sourceId": 47010,
     "databundleVersionId": 5031613,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30396,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat_minor": 0,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# **Homework 1: COVID-19 Cases Prediction (Regression)**"
   ],
   "metadata": {
    "id": "guE34D3Fj2R9"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Objectives:\n",
    "* Solve a regression problem with deep neural networks (DNN).\n",
    "* Understand basic DNN training tips.\n",
    "* Familiarize yourself with PyTorch.\n",
    "\n",
    "If you have any questions, please contact the TAs via TA hours, NTU COOL, or email to mlta-2023-spring@googlegroups.com"
   ],
   "metadata": {
    "id": "V57zhcTp1Xxb"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!nvidia-smi"
   ],
   "metadata": {
    "id": "GUATI4ONArv_",
    "execution": {
     "iopub.status.busy": "2023-02-12T07:30:52.741854Z",
     "iopub.execute_input": "2023-02-12T07:30:52.742902Z",
     "iopub.status.idle": "2023-02-12T07:30:53.95358Z",
     "shell.execute_reply.started": "2023-02-12T07:30:52.742777Z",
     "shell.execute_reply": "2023-02-12T07:30:53.95213Z"
    },
    "trusted": true,
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "44366831-cb7b-45b2-fc0b-24ef6d8e61a5"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/bin/bash: line 1: nvidia-smi: command not found\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Download data\n",
    "If the Google Drive links below do not work, you can use the dropbox link below or download data from [Kaggle](https://www.kaggle.com/t/a339b77fa5214978bfb8dde62d3151fe), and upload data manually to the workspace."
   ],
   "metadata": {
    "id": "Tm2aXcb-j9Fc"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# google drive link\n",
    "!pip install gdown\n",
    "!gdown --id '1BjXalPZxq9mybPKNjF3h5L3NcF7XKTS-' --output covid_train.csv\n",
    "!gdown --id '1B55t74Jg2E5FCsKCsUEkPKIuqaY7UIi1' --output covid_test.csv\n",
    "\n",
    "# dropbox link\n",
    "!wget -O covid_train.csv https://www.dropbox.com/s/lmy1riadzoy0ahw/covid.train.csv?dl=0\n",
    "!wget -O covid_test.csv https://www.dropbox.com/s/zalbw42lu4nmhr2/covid.test.csv?dl=0"
   ],
   "metadata": {
    "id": "YPmfl-awlKZA",
    "execution": {
     "iopub.status.busy": "2023-02-12T07:30:53.956273Z",
     "iopub.execute_input": "2023-02-12T07:30:53.956956Z",
     "iopub.status.idle": "2023-02-12T07:31:15.495174Z",
     "shell.execute_reply.started": "2023-02-12T07:30:53.956913Z",
     "shell.execute_reply": "2023-02-12T07:31:15.493786Z"
    },
    "trusted": true,
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "726e0807-6135-4722-8861-064f94bd3268"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: gdown in /usr/local/lib/python3.12/dist-packages (5.2.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from gdown) (4.13.5)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from gdown) (3.19.1)\n",
      "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.12/dist-packages (from gdown) (2.32.4)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from gdown) (4.67.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (2.8)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (4.15.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (2025.8.3)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
      "/usr/local/lib/python3.12/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
      "  warnings.warn(\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1BjXalPZxq9mybPKNjF3h5L3NcF7XKTS-\n",
      "To: /content/covid_train.csv\n",
      "100% 2.16M/2.16M [00:00<00:00, 11.1MB/s]\n",
      "/usr/local/lib/python3.12/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
      "  warnings.warn(\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1B55t74Jg2E5FCsKCsUEkPKIuqaY7UIi1\n",
      "To: /content/covid_test.csv\n",
      "100% 638k/638k [00:00<00:00, 94.9MB/s]\n",
      "--2025-09-12 14:49:12--  https://www.dropbox.com/s/lmy1riadzoy0ahw/covid.train.csv?dl=0\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.5.18, 2620:100:601d:18::a27d:512\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.5.18|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://www.dropbox.com/scl/fi/ewl0ff7lviu0s7f53jp9o/covid.train.csv?rlkey=pocojbo26thh2ncv0xkxfafiv&dl=0 [following]\n",
      "--2025-09-12 14:49:12--  https://www.dropbox.com/scl/fi/ewl0ff7lviu0s7f53jp9o/covid.train.csv?rlkey=pocojbo26thh2ncv0xkxfafiv&dl=0\n",
      "Reusing existing connection to www.dropbox.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://uce0d97cf6e1eef2aeda8048f4b2.dl.dropboxusercontent.com/cd/0/inline/CxPvV-l6zxW6Ym8xfJu2zzJZT9KL8oVwlb3diybfp_5qeHhIOazL9GD_J0sDxh3GoiUOz14rVSTDN_O6uITFBwfeblz8QEJhNcXCwp0uwPAc8ft1l0DVvKJVIMSCo-UIMQeAiJ_4mcGLkpo8e23tTmkK/file# [following]\n",
      "--2025-09-12 14:49:13--  https://uce0d97cf6e1eef2aeda8048f4b2.dl.dropboxusercontent.com/cd/0/inline/CxPvV-l6zxW6Ym8xfJu2zzJZT9KL8oVwlb3diybfp_5qeHhIOazL9GD_J0sDxh3GoiUOz14rVSTDN_O6uITFBwfeblz8QEJhNcXCwp0uwPAc8ft1l0DVvKJVIMSCo-UIMQeAiJ_4mcGLkpo8e23tTmkK/file\n",
      "Resolving uce0d97cf6e1eef2aeda8048f4b2.dl.dropboxusercontent.com (uce0d97cf6e1eef2aeda8048f4b2.dl.dropboxusercontent.com)... 162.125.5.15, 2620:100:601b:15::a27d:80f\n",
      "Connecting to uce0d97cf6e1eef2aeda8048f4b2.dl.dropboxusercontent.com (uce0d97cf6e1eef2aeda8048f4b2.dl.dropboxusercontent.com)|162.125.5.15|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2162766 (2.1M) [text/plain]\n",
      "Saving to: ‘covid_train.csv’\n",
      "\n",
      "covid_train.csv     100%[===================>]   2.06M  11.5MB/s    in 0.2s    \n",
      "\n",
      "2025-09-12 14:49:13 (11.5 MB/s) - ‘covid_train.csv’ saved [2162766/2162766]\n",
      "\n",
      "--2025-09-12 14:49:14--  https://www.dropbox.com/s/zalbw42lu4nmhr2/covid.test.csv?dl=0\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.5.18, 2620:100:601d:18::a27d:512\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.5.18|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://www.dropbox.com/scl/fi/0dewy98wqemuhraq1pi9s/covid.test.csv?rlkey=6x7r7z3hq8pvquke1bj8rqwgo&dl=0 [following]\n",
      "--2025-09-12 14:49:14--  https://www.dropbox.com/scl/fi/0dewy98wqemuhraq1pi9s/covid.test.csv?rlkey=6x7r7z3hq8pvquke1bj8rqwgo&dl=0\n",
      "Reusing existing connection to www.dropbox.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://uc9934e6eb9d5ab8c8a33bf97072.dl.dropboxusercontent.com/cd/0/inline/CxOvq7ijTCf4rg17JAsy6XY_5EGtlhERub6eclH7EM8wOUSsiQ4CvU1MdQI9nz8aT0THUVnEeVIzpdLkPcnQGFVoim26Qdv7hNYis6qlU3T6RBnRC_0KyelaLQIoDNca_eGdfsLywqhme5YxZISV-OPy/file# [following]\n",
      "--2025-09-12 14:49:14--  https://uc9934e6eb9d5ab8c8a33bf97072.dl.dropboxusercontent.com/cd/0/inline/CxOvq7ijTCf4rg17JAsy6XY_5EGtlhERub6eclH7EM8wOUSsiQ4CvU1MdQI9nz8aT0THUVnEeVIzpdLkPcnQGFVoim26Qdv7hNYis6qlU3T6RBnRC_0KyelaLQIoDNca_eGdfsLywqhme5YxZISV-OPy/file\n",
      "Resolving uc9934e6eb9d5ab8c8a33bf97072.dl.dropboxusercontent.com (uc9934e6eb9d5ab8c8a33bf97072.dl.dropboxusercontent.com)... 162.125.5.15, 2620:100:601d:15::a27d:50f\n",
      "Connecting to uc9934e6eb9d5ab8c8a33bf97072.dl.dropboxusercontent.com (uc9934e6eb9d5ab8c8a33bf97072.dl.dropboxusercontent.com)|162.125.5.15|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 638359 (623K) [text/plain]\n",
      "Saving to: ‘covid_test.csv’\n",
      "\n",
      "covid_test.csv      100%[===================>] 623.40K  --.-KB/s    in 0.09s   \n",
      "\n",
      "2025-09-12 14:49:15 (6.69 MB/s) - ‘covid_test.csv’ saved [638359/638359]\n",
      "\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Import packages"
   ],
   "metadata": {
    "id": "igqIMEgu64-F"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Numerical Operations\n",
    "import math\n",
    "from sched import scheduler\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Reading/Writing Data\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "\n",
    "# For Progress Bar\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "# For plotting learning curve\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# For selecting features\n",
    "from sklearn.feature_selection import SelectKBest, f_regression"
   ],
   "metadata": {
    "id": "xybQNYCXYu13",
    "execution": {
     "iopub.status.busy": "2023-02-12T07:31:16.478205Z",
     "iopub.execute_input": "2023-02-12T07:31:16.478628Z",
     "iopub.status.idle": "2023-02-12T07:31:18.240062Z",
     "shell.execute_reply.started": "2023-02-12T07:31:16.478584Z",
     "shell.execute_reply": "2023-02-12T07:31:18.239091Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2025-09-12T16:12:30.441526Z",
     "start_time": "2025-09-12T16:12:24.854Z"
    }
   },
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Some Utility Functions\n",
    "\n",
    "You do not need to modify this part."
   ],
   "metadata": {
    "id": "fTAVqRfc2KK3"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "'''作用：保证每次运行代码时的随机结果一致（可复现）'''\n",
    "def same_seed(seed):\n",
    "    '''Fixes random number generator seeds for reproducibility.'''\n",
    "    torch.backends.cudnn.deterministic = True #强制 cuDNN 使用确定性的算法（避免 GPU 上的随机性）\n",
    "    torch.backends.cudnn.benchmark = False #关闭 cuDNN 的自动优化（因为自动优化可能导致结果不一致）\n",
    "    np.random.seed(seed) #固定 NumPy 的随机数种子\n",
    "    torch.manual_seed(seed) #固定 PyTorch 的 CPU 随机数种子\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed) #固定 PyTorch 在所有 GPU 上的随机数种子（如果有 GPU）\n",
    "\n",
    "'''划分训练集和测试集'''\n",
    "def train_valid_split(data_set, valid_ratio, seed):#valid_ratio: the percent of test set\n",
    "    '''Split provided training data into training set and validation set'''\n",
    "    valid_set_size = int(valid_ratio * len(data_set))\n",
    "    train_set_size = len(data_set) - valid_set_size\n",
    "    train_set, valid_set = random_split(data_set, [train_set_size, valid_set_size], generator=torch.Generator().manual_seed(seed))#按指定大小随机划分数据集 确保划分结果固定（可复现）\n",
    "    return np.array(train_set), np.array(valid_set) #把结果转换为 NumPy 数组返回\n",
    "\n",
    "'''预测函数 作用：用训练好的模型对测试集进行预测'''\n",
    "def predict(test_loader, model, device):\n",
    "    model.eval() # Set your model to evaluation mode.将模型设置为 评估模式（关闭 dropout、batchnorm 的更新等）\n",
    "    preds = []\n",
    "    for x in tqdm(test_loader): #遍历测试数据加载器（tqdm 用于显示进度条）\n",
    "        x = x.to(device) #把数据放到 GPU 或 CPU 上\n",
    "        with torch.no_grad(): #禁用梯度计算，加快推理速度，节省显存\n",
    "            pred = model(x) #前向传播，得到预测结果\n",
    "            preds.append(pred.detach().cpu()) #把每批次的预测结果存到列表里\n",
    "    preds = torch.cat(preds, dim=0).numpy() #拼接所有批次结果，并转成 NumPy 数组\n",
    "    return preds"
   ],
   "metadata": {
    "id": "RbrcpfYN2I-H",
    "execution": {
     "iopub.status.busy": "2023-02-12T07:31:18.241353Z",
     "iopub.execute_input": "2023-02-12T07:31:18.241964Z",
     "iopub.status.idle": "2023-02-12T07:31:18.251864Z",
     "shell.execute_reply.started": "2023-02-12T07:31:18.241928Z",
     "shell.execute_reply": "2023-02-12T07:31:18.250938Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2025-09-12T16:13:09.345727Z",
     "start_time": "2025-09-12T16:13:09.322983Z"
    }
   },
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dataset"
   ],
   "metadata": {
    "id": "IqO3lTm78nNO"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class COVID19Dataset(Dataset):\n",
    "    '''\n",
    "    x: Features.\n",
    "    y: Targets, if none, do prediction.\n",
    "    '''\n",
    "    def __init__(self, x, y=None):\n",
    "        if y is None:\n",
    "            self.y = y #如果 y 为空（说明是 预测阶段），就不存标签\n",
    "        else:\n",
    "            self.y = torch.FloatTensor(y) #如果 y 不为空（说明是 训练/验证阶段），就把标签转成 torch.FloatTensor\n",
    "        self.x = torch.FloatTensor(x)\n",
    "\n",
    "    '''定义了当你用 dataset[i] 访问数据时返回什么'''\n",
    "    def __getitem__(self, idx):\n",
    "        if self.y is None:\n",
    "            return self.x[idx] #如果没有标签（预测阶段），只返回特征 x[idx]\n",
    "        else:\n",
    "            return self.x[idx], self.y[idx] #如果有标签（训练/验证阶段），返回 (x[idx], y[idx]) 这个二元组\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)"
   ],
   "metadata": {
    "id": "-mjaJM0wprMs",
    "execution": {
     "iopub.status.busy": "2023-02-12T07:31:18.253412Z",
     "iopub.execute_input": "2023-02-12T07:31:18.254031Z",
     "iopub.status.idle": "2023-02-12T07:31:18.262072Z",
     "shell.execute_reply.started": "2023-02-12T07:31:18.253994Z",
     "shell.execute_reply": "2023-02-12T07:31:18.261108Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2025-09-12T16:13:12.954933Z",
     "start_time": "2025-09-12T16:13:12.948744Z"
    }
   },
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Neural Network Model\n",
    "Try out different model architectures by modifying the class below."
   ],
   "metadata": {
    "id": "m73ooU75CL_j"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class My_Model(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(My_Model, self).__init__()\n",
    "        # TODO: modify model's structure, be aware of dimensions.\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_dim, 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8, 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        x = x.squeeze(1) # (B, 1) -> (B) 如果输出的形状是 (B, 1)（B 表示 batch 大小），就去掉第 1 维\n",
    "        # 变成 (B,)，方便后续计算（比如和标签 y 对齐）\n",
    "        return x"
   ],
   "metadata": {
    "id": "Qn97_WvvrEkG",
    "execution": {
     "iopub.status.busy": "2023-02-12T07:31:18.263546Z",
     "iopub.execute_input": "2023-02-12T07:31:18.263886Z",
     "iopub.status.idle": "2023-02-12T07:31:18.274148Z",
     "shell.execute_reply.started": "2023-02-12T07:31:18.263852Z",
     "shell.execute_reply": "2023-02-12T07:31:18.273078Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2025-09-12T16:13:15.729044Z",
     "start_time": "2025-09-12T16:13:15.723923Z"
    }
   },
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Feature Selection\n",
    "Choose features you deem useful by modifying the function below."
   ],
   "metadata": {
    "id": "x5-LKF6R8xeq"
   }
  },
  {
   "metadata": {
    "id": "sZA4qoKcZGYf",
    "ExecuteTime": {
     "end_time": "2025-09-12T16:13:18.418735Z",
     "start_time": "2025-09-12T16:13:18.413256Z"
    }
   },
   "cell_type": "code",
   "source": [
    "''' SelectKBest 和 f_regression 用于特征选择：\n",
    "    SelectKBest：挑出评分最高的前 K 个特征。\n",
    "    f_regression：衡量连续特征对连续目标的线性相关性(F-score)'''\n",
    "def select_top_features_regression(df_features, y, top_k):\n",
    "    #df_features：DataFrame 格式的特征矩阵 y：目标向量（连续值）top_k：想选出的特征数量\n",
    "    selector = SelectKBest(score_func=f_regression, k=top_k) #创建 SelectKBest 对象，指定评分函数为 f_regression\n",
    "    selector.fit(df_features, y) #调用 fit 方法计算每个特征与目标的 F-score\n",
    "\n",
    "    # 获取布尔掩码，True 表示被选中\n",
    "    mask = selector.get_support()\n",
    "    #selector.get_support() 返回一个布尔数组，标记哪些特征被选中（True 表示被选中）用这个布尔数组筛选出 列名，保存到 selected_columns\n",
    "\n",
    "    # 转换为整数索引\n",
    "    selected_indices = [i for i, x in enumerate(mask) if x]\n",
    "\n",
    "    #构建一个 DataFrame，把每个特征的 F-score 存起来，按分数从高到低排序 方便我们查看哪些特征最重要\n",
    "    feature_scores = pd.DataFrame({\n",
    "        \"feature\": df_features.columns,\n",
    "        \"score\": selector.scores_,\n",
    "        \"index\": range(len(df_features.columns))\n",
    "    }).sort_values(by=\"score\", ascending=False)\n",
    "\n",
    "\n",
    "    #打印前 top_k 个最重要特征及其 F-score，方便分析\n",
    "    print(f\"Top {top_k} features for regression:\")\n",
    "    print(feature_scores.head(top_k))\n",
    "\n",
    "    return selected_indices\n"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "id": "NvZiKfqiZGYf",
    "outputId": "994f2b6e-4a91-46aa-97fe-873b3ea8f993",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "ExecuteTime": {
     "end_time": "2025-09-12T16:13:44.570555Z",
     "start_time": "2025-09-12T16:13:44.386600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_origin = pd.read_csv(\"./data/covid_train.csv\").drop(columns = ['id']) #读取数据 去掉id列\n",
    "df_test = pd.read_csv(\"./data/covid_test.csv\").drop(columns = ['id'])\n",
    "\n",
    "target = df_origin['tested_positive']\n",
    "\n",
    "\n",
    "list_column_features = select_top_features_regression(df_origin, target, 16)\n",
    "#样本数远大于特征数（通常至少 10 倍以上）比较安全，避免过拟合\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 16 features for regression:\n",
      "              feature          score  index\n",
      "69  tested_positive.1  256663.154076     69\n",
      "87  tested_positive.2  104538.477954     87\n",
      "46       hh_cmnty_cli   13524.111217     46\n",
      "47     nohh_cmnty_cli   13432.693434     47\n",
      "36    wnohh_cmnty_cli   11640.642445     36\n",
      "65   nohh_cmnty_cli.1   11290.342757     65\n",
      "64     hh_cmnty_cli.1   11284.344366     64\n",
      "54  wnohh_cmnty_cli.1    9820.753823     54\n",
      "83   nohh_cmnty_cli.2    9438.214125     83\n",
      "82     hh_cmnty_cli.2    9370.679094     82\n",
      "72  wnohh_cmnty_cli.2    8248.330144     72\n",
      "34                cli    7577.491969     34\n",
      "35                ili    7564.492163     35\n",
      "52              cli.1    6448.391622     52\n",
      "53              ili.1    6433.907516     53\n",
      "70              cli.2    5435.753285     70\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "id": "EwkFOEQqZGYg",
    "outputId": "abe63e92-79af-4d15-91db-d6e21a363f25",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "ExecuteTime": {
     "end_time": "2025-09-12T16:13:48.895865Z",
     "start_time": "2025-09-12T16:13:48.841265Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_features = df_origin.iloc[:, list_column_features]\n",
    "\n",
    "# 取 df_features.columns 与 df_test.columns 的交集\n",
    "common_cols = df_features.columns.intersection(df_test.columns)\n",
    "\n",
    "df_test = df_test[common_cols]\n",
    "\n",
    "df_features"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "           cli       ili  wnohh_cmnty_cli  hh_cmnty_cli  nohh_cmnty_cli  \\\n",
       "0     1.509413  1.511169        18.583362     23.857405       18.757247   \n",
       "1     1.451798  1.460472        17.684337     22.897375       18.037506   \n",
       "2     1.308107  1.366300        17.194312     22.686202       17.583283   \n",
       "3     1.406672  1.488543        16.733442     22.484758       17.219515   \n",
       "4     1.381060  1.453365        16.580258     22.506261       17.128204   \n",
       "...        ...       ...              ...           ...             ...   \n",
       "3004  1.145430  1.174613        11.825744     15.376992       11.689749   \n",
       "3005  1.121511  1.150313        11.772172     15.420157       11.780117   \n",
       "3006  1.049163  1.077583        11.764646     15.416655       11.389769   \n",
       "3007  1.210881  1.239045        12.415059     15.755713       11.811906   \n",
       "3008  1.257293  1.238664        12.270085     15.538073       11.435870   \n",
       "\n",
       "         cli.1     ili.1  wnohh_cmnty_cli.1  hh_cmnty_cli.1  nohh_cmnty_cli.1  \\\n",
       "0     1.451798  1.460472          17.684337       22.897375         18.037506   \n",
       "1     1.308107  1.366300          17.194312       22.686202         17.583283   \n",
       "2     1.406672  1.488543          16.733442       22.484758         17.219515   \n",
       "3     1.381060  1.453365          16.580258       22.506261         17.128204   \n",
       "4     1.307137  1.400021          17.291188       22.369951         17.069263   \n",
       "...        ...       ...                ...             ...               ...   \n",
       "3004  1.121511  1.150313          11.772172       15.420157         11.780117   \n",
       "3005  1.049163  1.077583          11.764646       15.416655         11.389769   \n",
       "3006  1.210881  1.239045          12.415059       15.755713         11.811906   \n",
       "3007  1.257293  1.238664          12.270085       15.538073         11.435870   \n",
       "3008  1.647812  1.666511          13.535265       15.980730         11.592346   \n",
       "\n",
       "      tested_positive.1     cli.2  wnohh_cmnty_cli.2  hh_cmnty_cli.2  \\\n",
       "0             18.876155  1.308107          17.194312       22.686202   \n",
       "1             18.490787  1.406672          16.733442       22.484758   \n",
       "2             16.329253  1.381060          16.580258       22.506261   \n",
       "3             16.522931  1.307137          17.291188       22.369951   \n",
       "4             15.578501  1.206659          16.705053       21.440588   \n",
       "...                 ...       ...                ...             ...   \n",
       "3004           5.910541  1.049163          11.764646       15.416655   \n",
       "3005           6.487310  1.210881          12.415059       15.755713   \n",
       "3006           6.112827  1.257293          12.270085       15.538073   \n",
       "3007           6.151394  1.647812          13.535265       15.980730   \n",
       "3008           7.165580  1.704695          13.017151       15.777992   \n",
       "\n",
       "      nohh_cmnty_cli.2  tested_positive.2  \n",
       "0            17.583283          18.490787  \n",
       "1            17.219515          16.329253  \n",
       "2            17.128204          16.522931  \n",
       "3            17.069263          15.578501  \n",
       "4            16.207377          14.171920  \n",
       "...                ...                ...  \n",
       "3004         11.389769           6.487310  \n",
       "3005         11.811906           6.112827  \n",
       "3006         11.435870           6.151394  \n",
       "3007         11.592346           7.165580  \n",
       "3008         11.321163          10.535087  \n",
       "\n",
       "[3009 rows x 16 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cli</th>\n",
       "      <th>ili</th>\n",
       "      <th>wnohh_cmnty_cli</th>\n",
       "      <th>hh_cmnty_cli</th>\n",
       "      <th>nohh_cmnty_cli</th>\n",
       "      <th>cli.1</th>\n",
       "      <th>ili.1</th>\n",
       "      <th>wnohh_cmnty_cli.1</th>\n",
       "      <th>hh_cmnty_cli.1</th>\n",
       "      <th>nohh_cmnty_cli.1</th>\n",
       "      <th>tested_positive.1</th>\n",
       "      <th>cli.2</th>\n",
       "      <th>wnohh_cmnty_cli.2</th>\n",
       "      <th>hh_cmnty_cli.2</th>\n",
       "      <th>nohh_cmnty_cli.2</th>\n",
       "      <th>tested_positive.2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.509413</td>\n",
       "      <td>1.511169</td>\n",
       "      <td>18.583362</td>\n",
       "      <td>23.857405</td>\n",
       "      <td>18.757247</td>\n",
       "      <td>1.451798</td>\n",
       "      <td>1.460472</td>\n",
       "      <td>17.684337</td>\n",
       "      <td>22.897375</td>\n",
       "      <td>18.037506</td>\n",
       "      <td>18.876155</td>\n",
       "      <td>1.308107</td>\n",
       "      <td>17.194312</td>\n",
       "      <td>22.686202</td>\n",
       "      <td>17.583283</td>\n",
       "      <td>18.490787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.451798</td>\n",
       "      <td>1.460472</td>\n",
       "      <td>17.684337</td>\n",
       "      <td>22.897375</td>\n",
       "      <td>18.037506</td>\n",
       "      <td>1.308107</td>\n",
       "      <td>1.366300</td>\n",
       "      <td>17.194312</td>\n",
       "      <td>22.686202</td>\n",
       "      <td>17.583283</td>\n",
       "      <td>18.490787</td>\n",
       "      <td>1.406672</td>\n",
       "      <td>16.733442</td>\n",
       "      <td>22.484758</td>\n",
       "      <td>17.219515</td>\n",
       "      <td>16.329253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.308107</td>\n",
       "      <td>1.366300</td>\n",
       "      <td>17.194312</td>\n",
       "      <td>22.686202</td>\n",
       "      <td>17.583283</td>\n",
       "      <td>1.406672</td>\n",
       "      <td>1.488543</td>\n",
       "      <td>16.733442</td>\n",
       "      <td>22.484758</td>\n",
       "      <td>17.219515</td>\n",
       "      <td>16.329253</td>\n",
       "      <td>1.381060</td>\n",
       "      <td>16.580258</td>\n",
       "      <td>22.506261</td>\n",
       "      <td>17.128204</td>\n",
       "      <td>16.522931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.406672</td>\n",
       "      <td>1.488543</td>\n",
       "      <td>16.733442</td>\n",
       "      <td>22.484758</td>\n",
       "      <td>17.219515</td>\n",
       "      <td>1.381060</td>\n",
       "      <td>1.453365</td>\n",
       "      <td>16.580258</td>\n",
       "      <td>22.506261</td>\n",
       "      <td>17.128204</td>\n",
       "      <td>16.522931</td>\n",
       "      <td>1.307137</td>\n",
       "      <td>17.291188</td>\n",
       "      <td>22.369951</td>\n",
       "      <td>17.069263</td>\n",
       "      <td>15.578501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.381060</td>\n",
       "      <td>1.453365</td>\n",
       "      <td>16.580258</td>\n",
       "      <td>22.506261</td>\n",
       "      <td>17.128204</td>\n",
       "      <td>1.307137</td>\n",
       "      <td>1.400021</td>\n",
       "      <td>17.291188</td>\n",
       "      <td>22.369951</td>\n",
       "      <td>17.069263</td>\n",
       "      <td>15.578501</td>\n",
       "      <td>1.206659</td>\n",
       "      <td>16.705053</td>\n",
       "      <td>21.440588</td>\n",
       "      <td>16.207377</td>\n",
       "      <td>14.171920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3004</th>\n",
       "      <td>1.145430</td>\n",
       "      <td>1.174613</td>\n",
       "      <td>11.825744</td>\n",
       "      <td>15.376992</td>\n",
       "      <td>11.689749</td>\n",
       "      <td>1.121511</td>\n",
       "      <td>1.150313</td>\n",
       "      <td>11.772172</td>\n",
       "      <td>15.420157</td>\n",
       "      <td>11.780117</td>\n",
       "      <td>5.910541</td>\n",
       "      <td>1.049163</td>\n",
       "      <td>11.764646</td>\n",
       "      <td>15.416655</td>\n",
       "      <td>11.389769</td>\n",
       "      <td>6.487310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3005</th>\n",
       "      <td>1.121511</td>\n",
       "      <td>1.150313</td>\n",
       "      <td>11.772172</td>\n",
       "      <td>15.420157</td>\n",
       "      <td>11.780117</td>\n",
       "      <td>1.049163</td>\n",
       "      <td>1.077583</td>\n",
       "      <td>11.764646</td>\n",
       "      <td>15.416655</td>\n",
       "      <td>11.389769</td>\n",
       "      <td>6.487310</td>\n",
       "      <td>1.210881</td>\n",
       "      <td>12.415059</td>\n",
       "      <td>15.755713</td>\n",
       "      <td>11.811906</td>\n",
       "      <td>6.112827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3006</th>\n",
       "      <td>1.049163</td>\n",
       "      <td>1.077583</td>\n",
       "      <td>11.764646</td>\n",
       "      <td>15.416655</td>\n",
       "      <td>11.389769</td>\n",
       "      <td>1.210881</td>\n",
       "      <td>1.239045</td>\n",
       "      <td>12.415059</td>\n",
       "      <td>15.755713</td>\n",
       "      <td>11.811906</td>\n",
       "      <td>6.112827</td>\n",
       "      <td>1.257293</td>\n",
       "      <td>12.270085</td>\n",
       "      <td>15.538073</td>\n",
       "      <td>11.435870</td>\n",
       "      <td>6.151394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3007</th>\n",
       "      <td>1.210881</td>\n",
       "      <td>1.239045</td>\n",
       "      <td>12.415059</td>\n",
       "      <td>15.755713</td>\n",
       "      <td>11.811906</td>\n",
       "      <td>1.257293</td>\n",
       "      <td>1.238664</td>\n",
       "      <td>12.270085</td>\n",
       "      <td>15.538073</td>\n",
       "      <td>11.435870</td>\n",
       "      <td>6.151394</td>\n",
       "      <td>1.647812</td>\n",
       "      <td>13.535265</td>\n",
       "      <td>15.980730</td>\n",
       "      <td>11.592346</td>\n",
       "      <td>7.165580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3008</th>\n",
       "      <td>1.257293</td>\n",
       "      <td>1.238664</td>\n",
       "      <td>12.270085</td>\n",
       "      <td>15.538073</td>\n",
       "      <td>11.435870</td>\n",
       "      <td>1.647812</td>\n",
       "      <td>1.666511</td>\n",
       "      <td>13.535265</td>\n",
       "      <td>15.980730</td>\n",
       "      <td>11.592346</td>\n",
       "      <td>7.165580</td>\n",
       "      <td>1.704695</td>\n",
       "      <td>13.017151</td>\n",
       "      <td>15.777992</td>\n",
       "      <td>11.321163</td>\n",
       "      <td>10.535087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3009 rows × 16 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [
    "def select_feat(train_data, valid_data, test_data, feat_idx = None):\n",
    "    '''Selects useful features to perform regression'''\n",
    "    y_train, y_valid = train_data[:,-1], valid_data[:,-1]\n",
    "    raw_x_train, raw_x_valid, raw_x_test = train_data[:,:-1], valid_data[:,:-1], test_data\n",
    "\n",
    "    if feat_idx is None:\n",
    "        feat_idx = list(range(raw_x_train.shape[1]))\n",
    "     # TODO: Select suitable feature columns.\n",
    "\n",
    "    return raw_x_train[:,feat_idx], raw_x_valid[:,feat_idx], raw_x_test[:,feat_idx], y_train, y_valid"
   ],
   "metadata": {
    "id": "0FEnKRaIIeKp",
    "execution": {
     "iopub.status.busy": "2023-02-12T07:31:18.277047Z",
     "iopub.execute_input": "2023-02-12T07:31:18.277589Z",
     "iopub.status.idle": "2023-02-12T07:31:18.284837Z",
     "shell.execute_reply.started": "2023-02-12T07:31:18.277554Z",
     "shell.execute_reply": "2023-02-12T07:31:18.283918Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2025-09-12T16:13:51.172244Z",
     "start_time": "2025-09-12T16:13:51.168406Z"
    }
   },
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training Loop"
   ],
   "metadata": {
    "id": "kADIPNQ2Ih5X"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def trainer(train_loader, valid_loader, model, config, device):\n",
    "\n",
    "    criterion = nn.MSELoss(reduction='mean') # Define your loss function, do not modify this.\n",
    "    # reduction='mean' 表示对 batch 中的样本求平均\n",
    "\n",
    "    # Define your optimization algorithm.\n",
    "    # TODO: Please check https://pytorch.org/docs/stable/optim.html to get more available algorithms.\n",
    "    # TODO: L2 regularization (optimizer(weight decay...) or implement by your self).\n",
    "\n",
    "    '''选用Adam作为优化器'''\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config['learning_rate'], weight_decay=config['weight_decay'])\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2)\n",
    "\n",
    "    writer = SummaryWriter() # Writer of tensoboard.\n",
    "\n",
    "    if not os.path.isdir('./models'):\n",
    "        os.mkdir('./models') # Create directory of saving models.\n",
    "\n",
    "    n_epochs, best_loss, step, early_stop_count = config['n_epochs'], math.inf, 0, 0\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train() # Set your model to train mode. 训练模式，启用 dropout/batchnorm\n",
    "        loss_record = []\n",
    "\n",
    "        # tqdm is a package to visualize your training progress.\n",
    "        train_pbar = tqdm(train_loader, position=0, leave=True)\n",
    "\n",
    "        for x, y in train_pbar:\n",
    "            optimizer.zero_grad()               # Set gradient to zero.\n",
    "            x, y = x.to(device), y.to(device)   # Move your data to device.\n",
    "            pred = model(x)\n",
    "            loss = criterion(pred, y)\n",
    "            loss.backward()                     # Compute gradient(backpropagation).\n",
    "            optimizer.step()                    # Update parameters.\n",
    "            step += 1\n",
    "            loss_record.append(loss.detach().item())\n",
    "\n",
    "            # Display current epoch number and loss on tqdm progress bar.\n",
    "            train_pbar.set_description(f'Epoch [{epoch+1}/{n_epochs}]')\n",
    "            train_pbar.set_postfix({'loss': loss.detach().item()})\n",
    "\n",
    "        mean_train_loss = sum(loss_record)/len(loss_record)\n",
    "        writer.add_scalar('Loss/train', mean_train_loss, step)\n",
    "\n",
    "        model.eval() # Set your model to evaluation mode.\n",
    "        loss_record = []\n",
    "        for x, y in valid_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            with torch.no_grad():\n",
    "                pred = model(x)\n",
    "                loss = criterion(pred, y)\n",
    "\n",
    "            loss_record.append(loss.item())\n",
    "\n",
    "        mean_valid_loss = sum(loss_record)/len(loss_record)\n",
    "        print(f'Epoch [{epoch+1}/{n_epochs}]: Train loss: {mean_train_loss:.4f}, Valid loss: {mean_valid_loss:.4f}')\n",
    "        writer.add_scalar('Loss/valid', mean_valid_loss, step)\n",
    "\n",
    "        if mean_valid_loss < best_loss:\n",
    "            best_loss = mean_valid_loss\n",
    "            torch.save(model.state_dict(), config['save_path']) # Save your best model\n",
    "            print('Saving model with loss {:.3f}...'.format(best_loss))\n",
    "            early_stop_count = 0\n",
    "        else:\n",
    "            early_stop_count += 1\n",
    "\n",
    "        if early_stop_count >= config['early_stop']:\n",
    "            print('\\nModel is not improving, so we halt the training session.')\n",
    "            return"
   ],
   "metadata": {
    "id": "k4Rq8_TztAhq",
    "execution": {
     "iopub.status.busy": "2023-02-12T07:31:18.286341Z",
     "iopub.execute_input": "2023-02-12T07:31:18.286701Z",
     "iopub.status.idle": "2023-02-12T07:31:18.301211Z",
     "shell.execute_reply.started": "2023-02-12T07:31:18.286646Z",
     "shell.execute_reply": "2023-02-12T07:31:18.300217Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2025-09-12T16:13:53.542822Z",
     "start_time": "2025-09-12T16:13:53.531420Z"
    }
   },
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Configurations\n",
    "`config` contains hyper-parameters for training and the path to save your model."
   ],
   "metadata": {
    "id": "0pgkOh2e9UjE"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "config = {\n",
    "    \"weight_decay\": 1e-4,  # L2\n",
    "    'seed': 10101,      # Your seed number, you can pick your lucky number. :)\n",
    "    #'select_all': True,   # Whether to use all features.\n",
    "    'valid_ratio': 0.2,   # validation_size = train_size * valid_ratio\n",
    "    'n_epochs': 10000,     # Number of epochs.\n",
    "    'batch_size': 64,\n",
    "    'learning_rate': 1e-4,\n",
    "    'early_stop': 300,    # If model has not improved for this many consecutive epochs, stop training.\n",
    "    #通常 early_stop ≈ 训练轮数的 1%-5% 比较合理\n",
    "    'save_path': './models/model.ckpt'  # Your model will be saved here\n",
    "}"
   ],
   "metadata": {
    "id": "QoWPUahCtoT6",
    "execution": {
     "iopub.status.busy": "2023-02-12T07:31:18.304983Z",
     "iopub.execute_input": "2023-02-12T07:31:18.305345Z",
     "iopub.status.idle": "2023-02-12T07:31:18.361404Z",
     "shell.execute_reply.started": "2023-02-12T07:31:18.305313Z",
     "shell.execute_reply": "2023-02-12T07:31:18.36028Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2025-09-12T16:13:58.660778Z",
     "start_time": "2025-09-12T16:13:58.655040Z"
    }
   },
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dataloader\n",
    "Read data from files and set up training, validation, and testing sets. You do not need to modify this part."
   ],
   "metadata": {
    "id": "lrS-aJJh9XkW"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Set seed for reproducibility\n",
    "same_seed(config['seed'])\n",
    "\n",
    "\n",
    "# train_data size: 3009 x 89 (35 states + 18 features x 3 days)\n",
    "# test_data size: 997 x 88 (without last day's positive rate)\n",
    "train_data, test_data = pd.read_csv('./data/covid_train.csv').values, pd.read_csv('./data/covid_test.csv').values\n",
    "train_data, valid_data = train_valid_split(train_data, config['valid_ratio'], config['seed'])\n",
    "\n",
    "# Print out the data size.\n",
    "print(f\"\"\"train_data size: {train_data.shape}\n",
    "valid_data size: {valid_data.shape}\n",
    "test_data size: {test_data.shape}\"\"\")\n",
    "\n",
    "# Select features\n",
    "x_train, x_valid, x_test, y_train, y_valid = select_feat(train_data, valid_data, test_data, list_column_features)\n",
    "\n",
    "# Print out the number of features.\n",
    "print(f'number of features: {x_train.shape[1]}')\n",
    "\n",
    "train_dataset, valid_dataset, test_dataset = COVID19Dataset(x_train, y_train), \\\n",
    "                                            COVID19Dataset(x_valid, y_valid), \\\n",
    "                                            COVID19Dataset(x_test)\n",
    "\n",
    "# Pytorch data loader loads pytorch dataset into batches.\n",
    "train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True, pin_memory=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=config['batch_size'], shuffle=True, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=config['batch_size'], shuffle=False, pin_memory=True)"
   ],
   "metadata": {
    "id": "2jc7ZfDot2t9",
    "execution": {
     "iopub.status.busy": "2023-02-12T07:31:18.363178Z",
     "iopub.execute_input": "2023-02-12T07:31:18.363561Z",
     "iopub.status.idle": "2023-02-12T07:31:18.439675Z",
     "shell.execute_reply.started": "2023-02-12T07:31:18.363526Z",
     "shell.execute_reply": "2023-02-12T07:31:18.43872Z"
    },
    "trusted": true,
    "outputId": "d2cb5d3e-c6bc-4f38-de22-5605c93f75d2",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "ExecuteTime": {
     "end_time": "2025-09-12T16:14:14.013100Z",
     "start_time": "2025-09-12T16:14:13.909731Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data size: (2408, 89)\n",
      "valid_data size: (601, 89)\n",
      "test_data size: (997, 88)\n",
      "number of features: 16\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Start training!"
   ],
   "metadata": {
    "id": "0OBYgjCA-YwD"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model = My_Model(input_dim=x_train.shape[1]).to(device) # put your model and data on the same computation device.\n",
    "trainer(train_loader, valid_loader, model, config, device)"
   ],
   "metadata": {
    "id": "YdttVRkAfu2t",
    "execution": {
     "iopub.status.busy": "2023-02-12T07:31:18.441083Z",
     "iopub.execute_input": "2023-02-12T07:31:18.441534Z"
    },
    "trusted": true,
    "outputId": "539de17f-11d5-4ce6-f278-b02572bf16ae",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Testing\n",
    "The predictions of your model on testing set will be stored at `pred.csv`."
   ],
   "metadata": {
    "id": "yhAHGqC9-woK"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def save_pred(preds, file):\n",
    "    ''' Save predictions to specified file '''\n",
    "    with open(file, 'w') as fp:\n",
    "        writer = csv.writer(fp)\n",
    "        writer.writerow(['id', 'tested_positive'])\n",
    "        for i, p in enumerate(preds):\n",
    "            writer.writerow([i, p])\n",
    "\n",
    "model = My_Model(input_dim=x_train.shape[1]).to(device)\n",
    "model.load_state_dict(torch.load(config['save_path']))\n",
    "preds = predict(test_loader, model, device)\n",
    "save_pred(preds, 'pred.csv')"
   ],
   "metadata": {
    "id": "Q5eVdpbvAlAe",
    "trusted": true,
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "ae293720-0827-4760-f910-ccece596b596"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/16 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "100%|██████████| 16/16 [00:00<00:00, 1774.85it/s]\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Download\n",
    "\n",
    "Run this block to download the `pred.csv` by clicking."
   ],
   "metadata": {
    "id": "T_N-wBvVahc7"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink(r'pred.csv')"
   ],
   "metadata": {
    "id": "PmMnwrHeavJv",
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Reference\n",
    "This notebook uses code written by Heng-Jui Chang @ NTUEE (https://github.com/ga642381/ML2021-Spring/blob/main/HW01/HW01.ipynb)"
   ],
   "metadata": {
    "id": "IJ_k5rY0GvSV"
   }
  }
 ]
}
